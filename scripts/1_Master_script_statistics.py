########  1_Master_script_statistics.py #########

# Anderson M. Rodriguez
# 2025

# This script performs the statistically rigorous noise jitter (eta) sweep
# over multiple random seeds to demonstrate the superior robustness of
# the nonlinear (g=1.0) regime over the linear (g=0.0) regime.

# This script is designed to run in parallel across multiple cores

# The output generated by this will be the primary data generation for the repository to
# reproduce the results of the paper: "Morphological Computation in the Nonlinear Schrodinger Wavefield: Solitonic Dynamics Enable Noise-Tolerant, Self-Organizing Stability Inaccessible to Linear System"

import numpy as np
from scipy.fft import fftn, ifftn
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import time # For timing the parallel run
import concurrent.futures # For parallel execution on M2's multiple cores

# =================================================================
# 1. SIMULATION PARAMETERS
# =================================================================

# Grid parameters
NX, NY = 64, 64
L = 20.0  # Physical size of the domain (L x L)
DX, DY = L / NX, L / NY
x = np.linspace(-L / 2, L / 2, NX, endpoint=False)
y = np.linspace(-L / 2, L / 2, NY, endpoint=False)
X, Y = np.meshgrid(x, y)

# Time stepping and evolution baseline
DT = 0.001  # Time step size
T_BASELINE = 1.0  # Final time (T) fixed for this sweep

# Classification parameters
N_CLASSES = 4
N_SAMPLES_PER_CLASS = 100 # Total 400 samples per run (4 classes * 100)
N_TOTAL_SAMPLES = N_CLASSES * N_SAMPLES_PER_CLASS
# RANDOM_SEED is now handled by the seed argument in the functions

# Feature extraction (16x16 downsampling)
DOWN_FACTOR = 4  # 64 / 4 = 16
N_RESERVOIR_FEATURES = (NX // DOWN_FACTOR) * (NY // DOWN_FACTOR) + 4 # 256 + 4

# Fourier space setup (used for the linear step)
kx = 2 * np.pi / L * np.fft.fftfreq(NX) * NX
ky = 2 * np.pi / L * np.fft.fftfreq(NY) * NY
Kx, Ky = np.meshgrid(kx, ky)
K2 = Kx**2 + Ky**2

# Soliton initialization parameters
def get_initial_solitons(class_id):
    """Creates the base initial wavefield psi_0 for a given class."""
    amplitude_base = np.zeros((NX, NY), dtype=float)
    centers = [(L/4, L/4), (-L/4, -L/4)]
    for cx, cy in centers:
        R = np.sqrt((X - cx)**2 + (Y - cy)**2)
        amplitude_base += np.cosh(R)**(-1)

    k_map = {
        0: (0.5, 0.5),   # Diagonal
        1: (0.5, -0.5),  # Anti-diagonal
        2: (0.0, 1.0),   # Vertical
        3: (1.0, 0.0),   # Horizontal
    }
    kx_init, ky_init = k_map[class_id]
    phase_base = np.exp(1j * (kx_init * X + ky_init * Y))
    
    psi0 = amplitude_base * phase_base
    return psi0 / np.sqrt(np.sum(np.abs(psi0)**2)) * L # Normalize mass

# =================================================================
# 2. CORE DYNAMICS AND FEATURE EXTRACTION FUNCTIONS
# =================================================================

def apply_jitter(psi, eta, rng): # UPDATED: Accepts rng object
    """
    Adds uniform phase jitter in [-eta, eta], and a small class-independent Gaussian amplitude perturbation proportional to eta.
    Uses the provided numpy RandomState (rng) for reproducibility per seed/process.
    """
    if eta == 0.0:
        return psi
        
    # Phase jitter: Gaussian, zero mean, std dev eta
    delta_phi = rng.uniform(-eta, eta, (NX, NY)) # Uses rng
    
    # Amplitude jitter: 10% of eta * N(0,1)
    delta_A = 0.1 * eta * rng.normal(0, 1, (NX, NY)) # Uses rng
    
    amplitude = np.abs(psi) + delta_A
    phase = np.angle(psi) + delta_phi
    
    # Ensure amplitude remains non-negative
    amplitude[amplitude < 0] = 0.0 
    
    return amplitude * np.exp(1j * phase)

def nlse_step(psi_n, dt, g):
    """One step of the Split-Step Fourier Method (SSFM) for NLSE."""
    
    # 1. Linear half-step (Dispersion)
    psi_prime = ifftn(fftn(psi_n) * np.exp(-1j * K2 * dt / 4))
    
    # 2. Nonlinear full-step (Kerr term) -- This is G=0 if g=0
    psi_double_prime = psi_prime * np.exp(1j * g * np.abs(psi_prime)**2 * dt)
    
    # 3. Linear half-step (Dispersion)
    psi_next = ifftn(fftn(psi_double_prime) * np.exp(-1j * K2 * dt / 4))
    
    return psi_next

def extract_features(psi):
    """Extracts 4 control features and 260 reservoir features."""
    
    # --- Global Control Features (4 features) ---
    amplitude = np.abs(psi)
    phase = np.angle(psi)
    
    mass = np.sum(amplitude**2) * DX * DY
    
    # Calculate gradient energy (K) using finite differences (simplified)
    grad_psi_x = np.diff(psi, axis=0, append=psi[0:1, :]) / DX
    grad_psi_y = np.diff(psi, axis=1, append=psi[:, 0:1]) / DY
    K = np.sum(np.abs(grad_psi_x)**2 + np.abs(grad_psi_y)**2) * DX * DY
    
    # Simple phase statistics
    mean_cos = np.mean(np.cos(phase))
    mean_sin = np.mean(np.sin(phase))
    
    global_features = np.array([mean_cos, mean_sin, mass, K])
    
    # --- Reservoir Features (256 + 4 features) ---
    
    # Downsample amplitude (16x16 = 256 features)
    downsampled_amplitude = amplitude[::DOWN_FACTOR, ::DOWN_FACTOR].flatten()
    
    # Concatenate: 256 amplitude + 4 global features
    reservoir_features = np.concatenate([downsampled_amplitude, global_features])
    
    return global_features, reservoir_features

def run_experiment_batch(T_final, g_val, eta_val, seed): # UPDATED: Accepts seed
    """
    Generates data and runs the classification for a single (T, g, eta, seed) quartet.
    
    Returns: (control_accuracy, reservoir_accuracy)
    """
    N_STEPS = int(np.round(T_final / DT))
    # Create a RandomState object specific to this process/seed
    rng = np.random.RandomState(seed) 
    
    X_control = np.zeros((N_TOTAL_SAMPLES, 4))
    X_reservoir = np.zeros((N_TOTAL_SAMPLES, N_RESERVOIR_FEATURES))
    Y_labels = np.zeros(N_TOTAL_SAMPLES, dtype=int)
    
    # Data Generation Loop
    for i in range(N_TOTAL_SAMPLES):
        class_id = i // N_SAMPLES_PER_CLASS
        
        # 1. Initialize and Jitter
        psi_base = get_initial_solitons(class_id)
        # Pass the RandomState object for independent noise
        psi0_jittered = apply_jitter(psi_base, eta_val, rng) 
        
        # 2. Extract Control Features (from initial state)
        X_control[i, :] = extract_features(psi0_jittered)[0]
        
        # 3. Evolve (fixed g)
        psi = psi0_jittered
        for _ in range(N_STEPS):
            psi = nlse_step(psi, DT, g_val)
            
        # 4. Extract Reservoir Features (from evolved state)
        X_reservoir[i, :] = extract_features(psi)[1]
        Y_labels[i] = class_id

    # --- Classification ---
    
    # Train/Test Split (70/30) using the current seed for reproducibility
    X_res_train, X_res_test, y_train, y_test = train_test_split(
        X_reservoir, Y_labels, test_size=0.3, random_state=seed, stratify=Y_labels
    )
    X_con_train, X_con_test, _, _ = train_test_split(
        X_control, Y_labels, test_size=0.3, random_state=seed, stratify=Y_labels
    )
    
    # Reservoir Classifier
    # Use seed for classifier initialization
    clf_res = LogisticRegression(solver='lbfgs', random_state=seed, max_iter=5000) 
    clf_res.fit(X_res_train, y_train)
    acc_res = accuracy_score(y_test, clf_res.predict(X_res_test))
    
    # Control Classifier
    clf_con = LogisticRegression(solver='lbfgs', random_state=seed, max_iter=5000)
    clf_con.fit(X_con_train, y_train)
    acc_con = accuracy_score(y_test, clf_con.predict(X_con_test))
    
    return acc_con, acc_res

# =================================================================
# 3. PARALLEL EXECUTION FUNCTION
# =================================================================

def run_seed(seed, eta_sweep, T_final, G_nonlinear, G_linear):
    """
    Runs the full eta sweep for a single random seed.
    This function will be executed in parallel by ProcessPoolExecutor.
    Returns: (acc_res_nonlinear_seed, acc_res_linear_seed, acc_con_benchmark_seed)
    """
    
    N_ETA = len(eta_sweep)
    acc_res_nonlinear_seed = np.zeros(N_ETA)
    acc_res_linear_seed = np.zeros(N_ETA)
    acc_con_benchmark_seed = np.zeros(N_ETA)
    
    print(f"\n=======================================================")
    print(f"[Core {seed}] Starting sweep for Random Seed: {seed}")
    print(f"=======================================================")

    # Inner Jitter Sweep Loop
    for eta_idx, eta_val in enumerate(eta_sweep):
        
        # 1. RUN NONLINEAR RESERVOIR (g=1.0)
        acc_con_res, acc_res_res = run_experiment_batch(T_final, G_nonlinear, eta_val, seed)
        acc_res_nonlinear_seed[eta_idx] = acc_res_res
        
        # 2. RUN LINEAR RESERVOIR (g=0.0)
        acc_con_lin, acc_res_lin = run_experiment_batch(T_final, G_linear, eta_val, seed)
        acc_res_linear_seed[eta_idx] = acc_res_lin
        
        # 3. Save the Control Accuracy
        acc_con_benchmark_seed[eta_idx] = acc_con_lin
        
        print(f"[Core {seed}] Jitter \u03B7={eta_val:.4f} complete ({eta_idx + 1}/{N_ETA})")

    return (acc_res_nonlinear_seed, acc_res_linear_seed, acc_con_benchmark_seed)


# =================================================================
# 4. MAIN EXECUTION: PARALLEL SWEEP
# =================================================================

if __name__ == '__main__':
    
    # --- Sweep Parameters ---
    N_SEEDS = 10 
    SEEDS = np.arange(N_SEEDS) 
    ETA_SWEEP = np.linspace(0.1, 2.0, 15)
    T_FINAL = 1.0 
    G_NONLINEAR = 1.0 
    G_LINEAR = 0.0 
    
    # --- Result Arrays ---
    N_ETA = len(ETA_SWEEP)
    ACC_RES_NONLINEAR = np.zeros((N_SEEDS, N_ETA))
    ACC_RES_LINEAR = np.zeros((N_SEEDS, N_ETA))
    ACC_CON_BENCHMARK = np.zeros((N_SEEDS, N_ETA))

    print(f"Starting parallel sweep across {N_SEEDS} seeds using CPU cores.")
    print("Maximum workers set to None, using all available cores.")
    start_time = time.time()
    
    # Use ProcessPoolExecutor to run seeds in parallel
    with concurrent.futures.ProcessPoolExecutor(max_workers=None) as executor:
        
        # Map the run_seed function to the list of seeds
        # Each seed runs on an independent core
        future_to_seed = {
            executor.submit(
                run_seed, 
                seed, 
                ETA_SWEEP, 
                T_FINAL, 
                G_NONLINEAR, 
                G_LINEAR
            ): seed for seed in SEEDS
        }

        # Collect results as they complete
        for future in concurrent.futures.as_completed(future_to_seed):
            seed = future_to_seed[future]
            try:
                # Store the results into the final arrays
                idx = np.where(SEEDS == seed)[0][0]
                results = future.result()
                ACC_RES_NONLINEAR[idx, :] = results[0]
                ACC_RES_LINEAR[idx, :] = results[1]
                ACC_CON_BENCHMARK[idx, :] = results[2]
                
                # Report completion
                print(f"\n[Seed {seed}] **COMPLETED!**")
                elapsed = time.time() - start_time
                
                # Convert time to H:M:S format for a clean output
                h = int(elapsed // 3600)
                m = int((elapsed % 3600) // 60)
                s = int(elapsed % 60)
                print(f"--- Total elapsed wall-clock time so far: {h:02}h {m:02}m {s:02}s ---")
                
            except Exception as exc:
                print(f'[Seed {seed}] generated an exception: {exc}')
                # Optionally, re-raise if the error is critical: raise

    # --- Compute Mean and Std Dev ---
    print("\n\n=======================================================")
    print("Computing Final Statistical Results...")
    total_time = time.time() - start_time
    h = int(total_time // 3600)
    m = int((total_time % 3600) // 60)
    s = int(total_time % 60)
    print(f"Total Wall-Clock Time: {h:02}h {m:02}m {s:02}s")
    print("=======================================================")
    
    mean_nl = np.mean(ACC_RES_NONLINEAR, axis=0)
    std_nl = np.std(ACC_RES_NONLINEAR, axis=0)
    mean_lin = np.mean(ACC_RES_LINEAR, axis=0)
    std_lin = np.std(ACC_RES_LINEAR, axis=0)
    # The control accuracy is statistically averaged too, even though its signal is weak
    mean_con = np.mean(ACC_CON_BENCHMARK, axis=0) 
    std_con = np.std(ACC_CON_BENCHMARK, axis=0)
    
    # --- Save Results ---
    print("\nSaving Robustness Sweep Results (Mean/Std)...")
    DATA_PATH = 'data/'
    
    np.savez(DATA_PATH + 'etaV2paper1C_robustness_sweep_STATISTICAL.npz',
              eta_values=ETA_SWEEP,
              mean_acc_res_nonlinear=mean_nl,
              std_acc_res_nonlinear=std_nl,
              mean_acc_res_linear=mean_lin,
              std_acc_res_linear=std_lin,
              mean_acc_con_benchmark=mean_con,
              std_acc_con_benchmark=std_con)
    
    print("\nScript 1C complete. Data saved to etaV2paper1C_robustness_sweep_STATISTICAL.npz")
